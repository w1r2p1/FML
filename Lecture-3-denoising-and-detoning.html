<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Algorithmic trading and investment</title>
    <meta charset="utf-8" />
    <meta name="author" content="Barry Quinn" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/xaringanExtra-webcam/webcam.js"></script>
    <script id="xaringanExtra-webcam-options" type="application/json">{"width":"200","height":"200","margin":"1em"}</script>
    <link rel="stylesheet" href="css/sfah.css" type="text/css" />
    <link rel="stylesheet" href="css/fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




layout: true
  
&lt;div class="my-footer"&gt;&lt;span&gt;quinference.com&lt;/span&gt;&lt;/div&gt;

<div>
<style type="text/css">.xaringan-extra-logo {
width: 110px;
height: 128px;
z-index: 0;
background-image: url(img/redlogo.png);
background-size: contain;
background-repeat: no-repeat;
position: absolute;
top:1em;right:1em;
}
</style>
<script>(function () {
  let tries = 0
  function addLogo () {
    if (typeof slideshow === 'undefined') {
      tries += 1
      if (tries < 10) {
        setTimeout(addLogo, 100)
      }
    } else {
      document.querySelectorAll('.remark-slide-content:not(.title-slide):not(.inverse):not(.hide_logo)')
        .forEach(function (slide) {
          const logo = document.createElement('div')
          logo.classList = 'xaringan-extra-logo'
          logo.href = null
          slide.appendChild(logo)
        })
    }
  }
  document.addEventListener('DOMContentLoaded', addLogo)
})()</script>
</div>



---
name: ATL-title
class: inverse,left, middle
background-image: url(img/title-slide-img.png)
background-size: cover

# Algorithmic Trading and Investing (FIN7030)

# .fancy[Lecture 3: Extracting signal from noisy data]

.large[Barry Quinn PhD CStat | Queen's Management School | 2021-01-21]

&lt;!-- this ends up being the title slide since seal = FALSE--&gt;

---
class:inverse
# Learning outcomes 
- .large[Teaching mathematics]
- .large[The Jewel of the Matrix: Eigenvalues and Eigenvectors]
- .large.fancy[Mining the Jewel]
  -   .large[Marcenko-Pastur Theorem]
  - .large[Denoising and detoning financial covariance matrices]
  
- .large.fancy[Breathing breaks to aid learning]
---
class: inverse
## Teaching mathematical concepts

- Understanding machine learning requires familiarity with many simple mathematical concepts
- The goal of this course is to build your intuition about these notions without getting overly technical
- In particular I will limit mathematical notation , which can be off-putting for those without any mathematics background and isn't strictly necessary to explain things well
- Mostly, we will use coded practical example to illustrate the concepts
- This is a .large.fancy[**learning by doing**] approach when you can play around with the code yourself you understand underlying concepts
---
class: middle
# Why study denoising and detoning?

- .large[Covariance matrices are everywhere in finance.]
- .large[Empirical covariances measure the linear co-movement between a set of random variables]  
- .large[For example to estimate the linear comovement between FTSE 100 stocks you would gather 100 time series of each stocks returns]
- .large[They are used to:]

1. Run regressions
2. Estimate risk
3. Optimise portfolios
4. Simulate scenarios via Monte Carlo
5. Find clusters
6. Reduce the dimensionality of a set of potential predictors

---
class:middle
# &lt;i class="fas fa-gem"&gt;&lt;/i&gt; of financial matrices
## Eigenvalues and EigenVectors

- As discussed, the financial world is increasing becoming defined by *Big Data*, and data-driven decision making.
- As everything becomes defined by data, they are stored in matrices
- Success in the rapidly evolving quant finance industry increasing requires creative analytics and communications of complex and complication matrix-stored data.
- At the center of the matrix, through the complexities, lie its &lt;svg style="height:0.8em;top:.04em;position:relative;" viewBox="0 0 576 512"&gt;&lt;path d="M485.5 0L576 160H474.9L405.7 0h79.8zm-128 0l69.2 160H149.3L218.5 0h139zm-267 0h79.8l-69.2 160H0L90.5 0zM0 192h100.7l123 251.7c1.5 3.1-2.7 5.9-5 3.3L0 192zm148.2 0h279.6l-137 318.2c-1 2.4-4.5 2.4-5.5 0L148.2 192zm204.1 251.7l123-251.7H576L357.3 446.9c-2.3 2.7-6.5-.1-5-3.2z"/&gt;&lt;/svg&gt; the eigenvector and eignenvalues.
- The provide clarity and the true signal in the noisy data.
- Understand what they are is vital to be successful in modern finance. 
---
class:middle
# Deep dive into the nature of matrices
- One of the simplest matrix forms is a two-dimensional vector.
- It has two elements which each correspond to one coordinate on the two-dimensional plane.
-  For example each of the following vectors represent a movement on the y and x planes
![](img/vectors.png)
---
class:middle
# Deep dive into the nature of matrices
- In the matrix world, a linear transformation is performed by multiplying a vector by a matrix.
- Visually, the effect is to stretch (or squish) the coordinate system along two vectors
- For example the linear transformation matrix `\(\begin{bmatrix} 3 &amp; 1 \\ 1 &amp; 2 \end{bmatrix}\)` aligns the x-axis along the vector `\(\begin{bmatrix} 3&amp;1 \end{bmatrix}\)` (the first column) and the y-axis along the vector `\(\begin{bmatrix} 1&amp;2 \end{bmatrix}\)`
![](img/lineartransform.png)
.heat[The red lines show the transformation aligned to the y-axis]
.salt[The blue lines show the transformation aligned to the x-axis]
---
middle:class
# Deep dive into matrices
- Consider the vector  `\(\begin{bmatrix} -1&amp;-1 \end{bmatrix}\)` in the below figure
![](img/lineartransform2.png)
- After it is multiplied by the linear transformation matrix, it lands on the point `\(\begin{bmatrix} -4&amp;-3 \end{bmatrix}\)`
.saltinline[A vector's span is the line that runs through the vector forever]
.saltinline[When a vector undergoes a linear transformation usually it is knocked off of its span]

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt5[
*Eigenvectors* are vectors that do not get knocked off their span.  Instead, when eigenvectors are multiplied by a matrix, the eigenvector is simply scaled by a factor of the *eigenvalue*, landing somewhere else along the span
]
---
class:middle
# Deep dive into matrices
.pull-left[
![](img/eigenvector_messy.png)
 - Eigenvectors and eigenvalues are messy
 - They are seldom whole numbers and easy calculate
]
.pull-right[
- The nature of eigenvectors means that scaling an *Original* eigenvector in the same or directly opposite direction will yield yet another *scaled* eigenvector
![](img/eigenvector_scale.png)
]

---
class:middle
# Deep dive into the nature of matrices
.pull-left[
- In 3-D, the matrix describes a transformation of 3 axes,$x,y,z$, corresponding to the three coordinates that represent the transformation each coordinate undergoes.
- For this reason, *eigenvectors* and *eigenvalues* are only defined for square matrices
.footnote[A square matrix is a general `\(n\)` by `\(n\)` matrix describing the transformation of `\(n\)` axes, each corresponding to a coordinate with `\(n\)` elements]
![](img/3x3sqmatrix.png)
]
.pull-right[
- In order to find the eigenvector of a matrix, we need to find the eigenvalue
- From the definition of the eigenvalue, we can construct an equality `\(Ax=\lambda x\)`, where `\(A\)` represents the matrix and `\(\lambda\)` represents the eigenvalue.

![](img/matrixalgebra.png )    

.saltinline[The logic of this equality is that multiplying the eigenvector by the transformation matrix `\(x\)` should have the same effect as scaling it by eigenvalue `\(\lambda\)`]
]
---
class:middle

---
class: middle 
# Why study denoising and detoning?

- .large[Empirical covariance matrices are estimated with flawed, incomplete data which leads to estimates with an amount of noise]

- .large[Such noise can render calculations using covariance matrix estimates useless]

 .large[ In finance, we need a procedure to reduce this noise and enhance the signal **before** using in subsequent analysis like those listed previously]

---
class: middle
# .heat[Denoising] The Marcenko-Pastur Theorem
- This is an elegant mathematical theorem that can help *denoise* data by distinguishing random from non-random from nonrandom by means of the empirical correlation matrix of the data.

- The probability density function (pdf) of a Marcenko-Pastur distribution produces a set of eigenvalues which are randomly distributed.

- We can exploit this property to extract the non-random component of some empirical correlation matrix, thus removing the random noise.

.heat.fancy[Our goal is to learn how to discriminate between eigenvalues associated with noise components and eigenvalues associated with signal components]

---
class: top
## The Marcenko-Pastur Theorem in Python
.panelset[
.panel[.panel-name[ Set-up]

```r
library(reticulate)
matplotlib &lt;- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
```

- *Insert Python code chunk in RMarkdown file*


```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.neighbors.kde import KernelDensity
```

]
.panel[.panel-name[Define Python functions to test theorem]


```python
# ------------------------------
def mpPDF(var,q,pts):
  eMin,eMax=var*(1-(1./q)**.5)**2,var*(1+(1./q)**.5)**2
  eVal=np.linspace(eMin,eMax,pts)
  pdf=q/(2*np.pi*var*eVal)*((eMax-eVal)*(eVal-eMin))**.5
  pdf=pd.Series(pdf,index=eVal)
  return pdf
```

- This function is a principal component analysis function which will extract the Eigenvalues (principal components)

```python
def getPCA(matrix):
# Get eVal,eVec from a Hermitian Matrix
  eVal,eVec=np.linalg.eigh(matrix) # complete Hermitian (conjugate symmetric) or real symmetric matrix
  indices=eVal.argsort()[::-1] # arguments for sorting eVal in descending order
  eVal,eVec=eVal[indices],eVec[:,indices]
  eVal=np.diagflat(eVal) # indentity matrix with eignvalues as diagonal
  return eVal,eVec
```

- This function create a pdf for a series of supplied observations (obs)


```python
##---------------
def fitKDE(obs,bWidth=.25,kernel='gaussian',x=None):
# Fit kernel to a series of obs, and derive the probability of obs
# x is the array of values on which to fit KDE will be evaluate
  if len(obs.shape)==1:obs=obs.reshape(-1,1)
  kde=KernelDensity(kernel=kernel,bandwidth=bWidth).fit(obs)
  if x is None:x=np.unique(obs).reshape(-1,1)
  if len(x.shape)==1:x=x.reshape(-1,1)
  logProb=kde.score_samples(x) # log of probability density
  pdf=pd.Series(np.exp(logProb),index=x.flatten())
  return pdf
```
]
.panel[.panel-name[Test the theorem]


```python
# Create a random sample for testing
N = 1000
T = 10000
x=np.random.normal(0,1,size=(T,N))
cor=np.corrcoef(x,rowvar=0)
eVal0,eVec0=getPCA(cor)
pdf0=mpPDF(1.,q=x.shape[0]/float(x.shape[1]),pts=N) # Marcenko-Pastur pdf
pdf1=fitKDE(np.diag(eVal0),bWidth=.005) # empirical pdf
```
]
.panel[.panel-name[Visualising Marcenko-Pastur theorem]
.pull-left[
```
fig = plt.figure(figsize=(3,2))
plt.plot(pdf0.keys(), pdf0, color='r', label="Marcenko-Pastur pdf");
plt.plot(pdf1.keys(), pdf1, color='g', label="Empirical:KDE");
plt.legend(loc="upper right");
plt.show()
```
]
.pull-right[

```
## /opt/python/3.7.7/bin/python:1: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
```
]
]
]
---
class:middle

# Random Matrix with Signal
.panelset[
.panel[.panel-name[Explanation]
- In finance we are like to have a correlation matrix which is a mix of eigenvectors which are random and non-random (the signal)
- The code snippet builds a *fake* financial data covariance matrix that us not perfectly random.
- This *fake* data will only approximate the Marcenko-Pastur PDF, provides a way to extract the signal.
- Out of the `nCols` random variables that form the covariance matrix generated by `getRndCov`, only `nFact` contain some signal
- To weaken the signal (and make it more typical of financial data) we add that covariance matrix to a **purely random** matrix, with weight `alpha`
]
.panel[.panel-name[Python set-up]

```python
def getRndCov(nCols, nFacts): #nFacts - contains signal out of nCols
    w = np.random.normal(size=(nCols, nFacts))
    cov = np.dot(w, w.T) #random cov matrix, however not full rank
    cov += np.diag(np.random.uniform(size=nCols)) #full rank cov
    return cov

def cov2corr(cov):
    # Derive the correlation matrix from a covariance matrix
    std = np.sqrt(np.diag(cov))
    corr = cov/np.outer(std,std)
    corr[corr&lt;-1], corr[corr&gt;1] = -1,1 #for numerical errors
    return corr
    
def corr2cov(corr, std):
    cov = corr * np.outer(std, std)
    return cov
```
]
.panel[.panel[Create random matrix with signal]

```python
alpha, nCols, nFact, q = .995, 1000, 100, 10
pdf0 = mpPDF(1., q=x.shape[0]/float(x.shape[1]), pts=N)
cov = np.cov(np.random.normal(size=(nCols*q, nCols)), rowvar=0) #size = (1000*10,1000)
cov = alpha*cov+(1-alpha)*getRndCov(nCols, nFact) # noise + signal
corr0 = cov2corr(cov)
eVal01, eVec01 = getPCA(corr0)
```
]
]
---
class:top
# Fitting the Marcenko-Pastur Distribution
.panelset[
.panel[.panel-name[Explanation]
- The objective is to fit the MP distribution to find the variance value which minimises the sum of the squared differences between the analytical PDF and the kernel density estimate (KDE) of the observed eigenvalues
- The following code will report three important values:
- `eMax0`: the maximum expected eigenvalue beyond which the data is nonrandom
- `var0`: the variance value that minimises the sum of the square differences above
- `nFacts0`: the number of factors
]
.panel[.panel-name[Code to fit the MP pdf]

```python
from scipy.optimize import minimize
#Fit error
def errPDFs(var, eVal, q, bWidth, pts=1000):
    var = var[0]
    pdf0 = mpPDF(var, q, pts) #theoretical pdf
    pdf1 = fitKDE(eVal, bWidth, x=pdf0.index.values) #empirical pdf
    sse = np.sum((pdf1-pdf0)**2)
    print("sse:"+str(sse))
    return sse 
    
# find max random eVal by fitting Marcenko-Pastur dist
# and return variance
def findMaxEval(eVal, q, bWidth):
    out = minimize(lambda *x: errPDFs(*x), x0=np.array(0.5), args=(eVal, q, bWidth), bounds=((1E-5, 1-1E-5),))
    print("found errPDFs"+str(out['x'][0]))
    if out['success']: var = out['x'][0]
    else: var=1
    eMax = var*(1+(1./q)**.5)**2
    return eMax, var
```

]
.panel[.panel-name[Find optimal values]

```python
# Find optimal values
eMax0, var0 = findMaxEval(np.diag(eVal01), q, bWidth=.01);
```

```
## sse:744.7355142682438
## sse:744.735419269762
## sse:290.7957463390385
## sse:290.7957424533919
## sse:282.3394998615902
## sse:282.33950459149276
## sse:235.37064280616664
## sse:235.37065009124075
## sse:193.6415143203381
## sse:193.64147497081086
## sse:194.67634305635184
## sse:194.67635225207653
## sse:20.146201025473594
## sse:20.146204395008223
## sse:7036642712506.261
## sse:7022590508897.954
## sse:1230.0986453620005
## sse:1230.0985057559374
## sse:18.460782827173635
## sse:18.46078267193625
## sse:290.7957463390385
## sse:290.7957424533919
## sse:18.46781957818509
## sse:18.467819853148185
## sse:18.457543902587865
## sse:18.45754390259085
## sse:18.45754390258828
## sse:18.457543902588164
## sse:18.457543902587723
## sse:18.45754390259009
## found errPDFs0.6766758019302465
```

```python
nFacts0 = eVal01.shape[0]-np.diag(eVal01)[::-1].searchsorted(eMax0);
pdf0 = mpPDF(var0, q=x.shape[0]/float(x.shape[1]), pts=N)
pdf2=fitKDE(np.diag(eVal01),bWidth=.005)
```
]
.panel[.panel-name[Visualise results]


```
# Plot results
fig = plt.figure()
ax  = fig.add_subplot(111)
hist_data=np.diag(eVal01)
ax.hist(hist_data, density = True, bins=50); # Histogram the eigenvalues
plt.plot(pdf0.keys(), pdf0, color='r', label="Marcenko-Pastur pdf");
# plt.plot(pdf1.keys(), pdf1, color='g', label="Empirical:KDE");
plt.plot(pdf2.keys(), pdf2, color='b', label="Eigenvalues of random-matrix with signal");
plt.legend(loc="upper right");
```

```python
plt.show()    
```

```
## /opt/python/3.7.7/bin/python:1: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
```

]
]
---
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
